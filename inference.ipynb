{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHNth9l/J7pwQI+6byX1rL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anarlavrenov/n2/blob/main/inference_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptM9b22nGs9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540c67dd-e6c0-482e-af06-d949212d050b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Загрузка модели и параметров оптимизатора\n",
        "\n",
        "# !gdown --no-check-certificate \"https://drive.google.com/uc?export=download&id=10bx8VZ4LVJz1JnU2qklgdN0FsS9KM-3d\" -O LibriSpeech_100_model.pth\n",
        "# !gdown --no-check-certificate \"https://drive.google.com/uc?export=download&id=10cfMP77QvQ8jl1_7OJCMKraXIQLpZW6h\" -O LibriSpeech_100_optimizer.pth\n",
        "\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка тестового датасета LJSPEECH\n",
        "import torchaudio\n",
        "\n",
        "dataset = torchaudio.datasets.LJSPEECH(\".\", download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UItfnKI8rZeD",
        "outputId": "1ecd3d22-0ec5-4634-cbdd-93a43c7eb7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.56G/2.56G [02:34<00:00, 17.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание словаря из символов\n",
        "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter\n",
        "\n",
        "chars = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
        "\n",
        "counter = Counter(chars) # Считает кол-во уникальных токенов в списке, возвращает словарь\n",
        "vocab = vocab(counter)\n",
        "unk_token = \"\"\n",
        "vocab.insert_token(unk_token, 0)\n",
        "vocab.set_default_index(vocab[unk_token])"
      ],
      "metadata": {
        "id": "qFDY2BgnHeg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Препроцессинг аудио\n",
        "import torchaudio\n",
        "\n",
        "win_length = 256\n",
        "hop_length = 160\n",
        "n_fft = 384\n",
        "\n",
        "def preprocess_audio(waveform, orig_sr):\n",
        "\n",
        "  # Получение waveform и sample_rate\n",
        "  waveform = torchaudio.functional.resample(waveform, orig_freq=orig_sr, new_freq=16000)\n",
        "  waveform = torch.squeeze(waveform, dim=0)\n",
        "  waveform = waveform.to(torch.float32)\n",
        "  # Получение спектрограммы\n",
        "  transforms = torchaudio.transforms.Spectrogram(\n",
        "      win_length=win_length,\n",
        "      hop_length=hop_length,\n",
        "      n_fft=n_fft,\n",
        "      power=None\n",
        "  )\n",
        "  spectrogram = transforms(waveform)\n",
        "  # Перестановка на timeframes, n_mels\n",
        "  spectrogram = torch.transpose(spectrogram, 1, 0)\n",
        "\n",
        "  # Получение магнитуды\n",
        "  spectrogram = torch.abs(spectrogram)\n",
        "  spectrogram = torch.pow(spectrogram, 0.5)\n",
        "  # Нормализация\n",
        "  means = torch.mean(spectrogram, dim=1, keepdims=True)\n",
        "  stddevs = torch.std(spectrogram, dim=1, keepdims=True)\n",
        "  spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "  return spectrogram"
      ],
      "metadata": {
        "id": "nH58CLcBHuKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "\n",
        "  wf, sr, text, *_ = zip(*batch)\n",
        "\n",
        "  spectrograms = []\n",
        "  tokens = []\n",
        "\n",
        "  # Обработка спектрограммы\n",
        "  for w in wf:\n",
        "    spectrogram = preprocess_audio(w)\n",
        "    spectrogram = torch.nn.functional.pad(\n",
        "        spectrogram, (0, 0, 0, 2048-spectrogram.shape[0]), \"constant\", 0\n",
        "    ) # (слева, справа, сверху, снизу)\n",
        "\n",
        "    spectrograms.append(spectrogram)\n",
        "\n",
        "  # Обработка текста\n",
        "  for t in text:\n",
        "    t = t.lower()\n",
        "    t = [vocab[x] for x in t]\n",
        "    t = torch.nn.functional.pad(\n",
        "        torch.tensor(t), (0, 216-len(t)), \"constant\", 0\n",
        "    )\n",
        "    tokens.append(t)\n",
        "\n",
        "  spectrograms = torch.stack(spectrograms, dim=0)\n",
        "  tokens = torch.stack(tokens, dim=0)\n",
        "\n",
        "  return spectrograms, tokens"
      ],
      "metadata": {
        "id": "ErjDwSm0tA56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, rnn_layers, rnn_units, output_dim):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(\n",
        "        in_channels=1,\n",
        "        out_channels=32,\n",
        "        kernel_size=(11, 41),\n",
        "        padding=(5, 20),\n",
        "        stride=(2, 2),\n",
        "        bias=False\n",
        "        )\n",
        "\n",
        "    self.conv2 = torch.nn.Conv2d(\n",
        "      in_channels=32,\n",
        "      out_channels=32,\n",
        "      kernel_size=(11, 21),\n",
        "      padding=(5, 10),\n",
        "      stride=(1, 2),\n",
        "      bias=False\n",
        "    )\n",
        "\n",
        "    self.conv3 = torch.nn.Conv2d(\n",
        "      in_channels=32,\n",
        "      out_channels=64,\n",
        "      kernel_size=(11, 21),\n",
        "      padding=(5, 10),\n",
        "      stride=(1, 2),\n",
        "      bias=False\n",
        "    )\n",
        "\n",
        "    self.lstm = torch.nn.LSTM(\n",
        "        input_size=64 * 25,\n",
        "        hidden_size=rnn_units,\n",
        "        num_layers=rnn_layers,\n",
        "        bidirectional=True,\n",
        "        dropout=0.5,\n",
        "        batch_first=True,\n",
        "        bias=True\n",
        "    )\n",
        "\n",
        "    self.fc1 = torch.nn.Linear(\n",
        "        in_features=rnn_units * 2,\n",
        "        out_features=rnn_units * 2\n",
        "    )\n",
        "\n",
        "    self.fc2 = torch.nn.Linear(\n",
        "        in_features=rnn_units * 2,\n",
        "        out_features=output_dim + 1\n",
        "    )\n",
        "\n",
        "    self.bn1 = torch.nn.BatchNorm2d(num_features=32)\n",
        "    self.bn2 = torch.nn.BatchNorm2d(num_features=32)\n",
        "    self.bn3 = torch.nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "    self.dp = torch.nn.Dropout(p=0.5)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "\n",
        "  def forward(self, src):\n",
        "    src = src.unsqueeze(1)\n",
        "\n",
        "    src = self.relu(self.bn1(self.conv1(src))) # [batch_size, filters, height, width]\n",
        "    src = self.relu(self.bn2(self.conv2(src))) # [batch_size, filters, height, width]\n",
        "    src = self.relu(self.bn3(self.conv3(src))) # [batch_size, filters, height, width]\n",
        "    src = src.permute(0, 2, 1, 3)\n",
        "\n",
        "    src = src.reshape(src.shape[0], src.shape[1], src.shape[2] * src.shape[3]) # [batch_size, height, filters * width]\n",
        "    rnn_out, (ht, ct) = self.lstm(src) # [batch_size, height, rnn_units * 2]\n",
        "\n",
        "    fc_out = self.fc1(rnn_out) # [batch_size, height, rnn_units * 2]\n",
        "    fc_out = self.relu(fc_out)\n",
        "    fc_out = self.dp(fc_out)\n",
        "    out = self.fc2(fc_out) # [batch_size, height, output_dim]\n",
        "\n",
        "    out = out.permute(1, 0, 2) # [height, batch_size, output_dim]\n",
        "\n",
        "    out = torch.nn.functional.log_softmax(out, dim=2) # [batch_size, height, output_dim]\n",
        "\n",
        "    return out\n",
        "\n",
        "# Загрузка модели\n",
        "model = torch.load(\"/content/model.pth\").to(device)"
      ],
      "metadata": {
        "id": "9KzilkneH8tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CTCGreedyDecoder(torch.nn.Module):\n",
        "  def __init__(self, labels, blank=0):\n",
        "    super(CTCGreedyDecoder, self).__init__()\n",
        "\n",
        "    self.labels = labels\n",
        "    self.blank = blank\n",
        "\n",
        "  def forward(self, outputs):\n",
        "\n",
        "    indices = torch.argmax(outputs, dim=-1)\n",
        "    indices = torch.unique_consecutive(indices, dim=0)\n",
        "    indices = [token for token in indices if token != self.blank]\n",
        "    joined = \"\".join([self.labels[idx] for idx in indices])\n",
        "    splt = joined.strip().split()\n",
        "\n",
        "    return \" \".join(splt)\n",
        "\n",
        "greedy_decoder = CTCGreedyDecoder(labels=vocab.get_itos())"
      ],
      "metadata": {
        "id": "wnpwkP-UJVGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    drop_last=True,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "4ZfbYnpotLJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Рассчет метрик WER & CER\n",
        "!pip install jiwer -q\n",
        "\n",
        "from jiwer import wer, cer\n",
        "from tqdm import tqdm\n",
        "\n",
        "model.eval()\n",
        "\n",
        "wer_scores = []\n",
        "cer_scores = []\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch in tqdm(loader, desc=\"Calculating WER & CER scores\"):\n",
        "    val_src, val_tgt = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "    for idx in range(val_src.shape[0]):\n",
        "\n",
        "      y_pred = model(val_src[idx].unsqueeze(0))\n",
        "\n",
        "      y_pred = greedy_decoder(y_pred)\n",
        "      y_true = \"\".join([vocab.get_itos()[i] for i in val_tgt[idx]])\n",
        "\n",
        "      wer_scores.append(wer(y_pred, y_true))\n",
        "      cer_scores.append(cer(y_pred, y_true))\n",
        "\n",
        "wer_score = (sum(wer_scores) / len(wer_scores))\n",
        "cer_score = (sum(cer_scores) / len(cer_scores))\n",
        "\n",
        "print(f\"\\n\\n wer score: {wer_score:.2f}, cer score: {cer_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A4AHcAJtR29",
        "outputId": "c0e44daf-9cb3-4238-cf4f-5ca6e36cb59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating WER & CER scores: 100%|██████████| 204/204 [55:10<00:00, 16.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " wer score: 0.37, cer score: 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Показ прогнозов\n",
        "def show_result(idx):\n",
        "  y_pred = model(val_src[idx].unsqueeze(0))\n",
        "  y_pred = greedy_decoder(y_pred)\n",
        "  y_true = \"\".join([vocab.get_itos()[i] for i in val_tgt[idx]])\n",
        "\n",
        "  print(f\"pred: {y_pred}\")\n",
        "  print(f\"true: {y_true}\")\n",
        "\n",
        "samples = torch.randint(1, 64, (5, ))\n",
        "\n",
        "for sample in samples:\n",
        "  show_result(sample)\n",
        "  print(\"*\" * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQAfn4aRFQXc",
        "outputId": "f11241e2-eadc-4e83-8946-48efedcc818e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: studie's indicate that there is some utility ind attempting to desg nate certain buildings as in volving a higher risk of an others\n",
            "true: the studies indicate that there is some utility in attempting to designate certain buildings as involving a higher risk than others\n",
            "****************************************************************************************************\n",
            "pred: ad coordination might be achieved to a greater extet than seems now to be contemplated without intefearence but the primary mession of ecagent se involved\n",
            "true: that coordination might be achieved to a greater extent than seems now to be contemplated without interference with the primary mission of each agency involved\n",
            "****************************************************************************************************\n",
            "pred: at rickon instructions might come into the hands of local newspapers to the prejidice of the procautions described\n",
            "true: that written instructions might come into the hands of local newspapers to the prejudice of the precautions described\n",
            "****************************************************************************************************\n",
            "pred: and requests for inditional personal were not made because of the studies than being conducted\n",
            "true: and requests for additional personnel were not made because of the studies then being conducted\n",
            "****************************************************************************************************\n",
            "pred: caselon of e cef be i agent average twenty to twenty five and he felt that this was high\n",
            "true: the caseload of each fbi agent averaged  to  and he felt that this was high\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    }
  ]
}
